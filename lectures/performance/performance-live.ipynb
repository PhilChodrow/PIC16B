{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04a3a86a",
   "metadata": {},
   "source": [
    "# Some Notes on Performance for Python Code\n",
    "\n",
    "<figure class=\"image\" style=\"width:30%\">\n",
    "  <img src=\"https://raw.githubusercontent.com/PhilChodrow/PIC16B/master/_images/faster.jpeg\" alt=\"Picard, with caption 'Make it faster, Number One.\">\n",
    "    <figcaption><i>What we're doing today.</i></figcaption>\n",
    "</figure>\n",
    "\n",
    "In this one-off lecture, we'll consider a question that often pops up when writing Python code: \n",
    "\n",
    "> How can I make my code *faster*? \n",
    "\n",
    "There are a large number of things to keep in mind when considering how to make our code performant. Today, we'll briefly survey just a few of the possibilities. Here's a [nice list](https://stackify.com/20-simple-python-performance-tuning-tips/) of useful tips. \n",
    "\n",
    "## Numpy and Pandas\n",
    "\n",
    "As you know, code that is primarily related to numerical computations or manipulation of rectangular data should almost always be performed in Numpy or Pandas. Both of these tools bring considerable performance improvements over base Python code in the situations to which they are suited, and should generally be used when possible. I won't be talking more about these topics today, but please remember that using these tools for appropriate problems is one of the easiest and biggest wins for performance. \n",
    "\n",
    "## 0. Should I Write This Code? \n",
    "\n",
    "So, you've got a task that you'd like to perform in Python, and you can see the outlines of a good code solution. *Should you write code for your solution?* Maybe! Before you do, take a moment to look around and see what else might be available. Public and well-established functions will almost always be more reliable and performant than what you hack together. Use them whenever possible! \n",
    "\n",
    "Suppose we'd like to iterate through all possible pairs of elements from a list. Here's one way: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf324b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "captains = [\"Picard\", \"Sisko\", \"Janeway\", \"Archer\", \"Georgiou\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "951f90fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Picard', 'Picard'),\n",
       " ('Picard', 'Sisko'),\n",
       " ('Picard', 'Janeway'),\n",
       " ('Picard', 'Archer'),\n",
       " ('Picard', 'Georgiou'),\n",
       " ('Sisko', 'Picard'),\n",
       " ('Sisko', 'Sisko'),\n",
       " ('Sisko', 'Janeway'),\n",
       " ('Sisko', 'Archer'),\n",
       " ('Sisko', 'Georgiou'),\n",
       " ('Janeway', 'Picard'),\n",
       " ('Janeway', 'Sisko'),\n",
       " ('Janeway', 'Janeway'),\n",
       " ('Janeway', 'Archer'),\n",
       " ('Janeway', 'Georgiou'),\n",
       " ('Archer', 'Picard'),\n",
       " ('Archer', 'Sisko'),\n",
       " ('Archer', 'Janeway'),\n",
       " ('Archer', 'Archer'),\n",
       " ('Archer', 'Georgiou'),\n",
       " ('Georgiou', 'Picard'),\n",
       " ('Georgiou', 'Sisko'),\n",
       " ('Georgiou', 'Janeway'),\n",
       " ('Georgiou', 'Archer'),\n",
       " ('Georgiou', 'Georgiou')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1cb1b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.49 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "8.73 µs ± 4.46 µs per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0048c251",
   "metadata": {},
   "source": [
    "This code looks pretty fast, but a quick Google search for \"iterate through all pairs python\" turns up this [StackOverflow](https://stackoverflow.com/questions/942543/operation-on-every-pair-of-element-in-a-list/37907649) post, indicating that I should use `itertools.product()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9334a356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c00e8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.72 µs ± 99 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f7c2873",
   "metadata": {},
   "source": [
    "Use of `itertools.product()` saved me from writing some code, and is also noticeably faster. Both kinds of savings will tend to become more pronounced the more complex the task that you need to accomplish. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dbd67b",
   "metadata": {},
   "source": [
    "## 1. *Should* I Optimize This Code? \n",
    "\n",
    "Let's now suppose that you've done your research and determined that you do need to write up your own solution. Indeed, you've already done it. Great job! But now we face the next question: should you spend time making your code faster? \n",
    "\n",
    "<figure class=\"image\" style=\"width:30%\">\n",
    "  <img src=\"https://media.makeameme.org/created/one-does-not-d06ab06f16.jpg\" alt=\"Boromir, with caption 'One does not simply make some code run fast.\">\n",
    "    <figcaption><i></i></figcaption>\n",
    "</figure>\n",
    "\n",
    "When creating any kind of code product, we face various decisions about how to best allocate our time and energy. Making code faster can be a very helpful or even necessary thing to do. Before choosing to spend effort optimizing your code, ask yourself the following questions: \n",
    "\n",
    "1. Does my code run in practical (non-annoying) time on realistic cases? \n",
    "2. How many times will my code be run? By how many people? \n",
    "3. Is the code that I am considering optimizing a major part of my overall project? \n",
    "\n",
    "This third question is especially important. Maybe you have a function that takes 1 ms to run. This might be considered relatively slow! Maybe you can improve it to 0.1 ms with effort, a 10x speed up. But if that function will only be called once or twice in a given interaction, your user is unlikely to notice the difference. A function that takes 1 µs but which is called 1M times is much more important to optimize, and even a 2x speedup will have a much larger benefit for your user. \n",
    "\n",
    "## 2. *Which* Code Should I Optimize? \n",
    "\n",
    "Suppose you have a function or even an entire program. Which parts of it need your attention? A *profiler* can be used to analyze your code and provide important information, like: \n",
    "\n",
    "1. How many times are various functions within your code called? \n",
    "2. How much time does each function take per call? \n",
    "\n",
    "There are a number of different profilers available for Python. `cProfile` comes bundled with all modern Python distributions and is a traditional choice. We'll illustrate cProfile here. Another option I found is [Yappi](https://pypi.org/project/yappi/) (Yet Another Python ProfIler), which has several advanced features. It can be installed via the Anaconda Environments Pane. \n",
    "\n",
    "Let's write a simple function to count distinct elements in a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd126870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87b14e12",
   "metadata": {},
   "source": [
    "Here's some data on which we'll call our function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21baf799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3800, 32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"\"\"\n",
    "Space, the final frontier\n",
    "These are the voyages of the Starship Enterprise\n",
    "Its five year mission\n",
    "To explore strange new worlds\n",
    "To seek out new life\n",
    "And new civilizations\n",
    "To boldly go where no one has gone before\"\"\"\n",
    "\n",
    "L = (s*100).lower().split()\n",
    "len(L), len(set(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff43bb3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'space,': 100,\n",
       " 'the': 300,\n",
       " 'final': 100,\n",
       " 'frontier': 100,\n",
       " 'these': 100,\n",
       " 'are': 100,\n",
       " 'voyages': 100,\n",
       " 'of': 100,\n",
       " 'starship': 100,\n",
       " 'enterprise': 100,\n",
       " 'its': 100,\n",
       " 'five': 100,\n",
       " 'year': 100,\n",
       " 'mission': 100,\n",
       " 'to': 300,\n",
       " 'explore': 100,\n",
       " 'strange': 100,\n",
       " 'new': 300,\n",
       " 'worlds': 100,\n",
       " 'seek': 100,\n",
       " 'out': 100,\n",
       " 'life': 100,\n",
       " 'and': 100,\n",
       " 'civilizations': 100,\n",
       " 'boldly': 100,\n",
       " 'go': 100,\n",
       " 'where': 100,\n",
       " 'no': 100,\n",
       " 'one': 100,\n",
       " 'has': 100,\n",
       " 'gone': 100,\n",
       " 'before': 100}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e213eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296 ms ± 14.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c052eae8",
   "metadata": {},
   "source": [
    "Hmmm, that's pretty slow. Was it the way that we're updating our dictionary, maybe? Should we seek a faster method than `count()` for actually counting objects? For these kinds of questions, profiling is exactly what we need: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd21e97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         7604 function calls in 0.349 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "     3800    0.333    0.000    0.333    0.000 {method 'count' of 'list' objects}\n",
      "        1    0.013    0.013    0.349    0.349 <ipython-input-6-80eaeb576a90>:1(count_list)\n",
      "     3800    0.003    0.000    0.003    0.000 {method 'update' of 'dict' objects}\n",
      "        1    0.000    0.000    0.349    0.349 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.349    0.349 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b13ba6a",
   "metadata": {},
   "source": [
    "The cProfile output contains lines for each of the function calls that the profiler was able to detect (note: it doesn't always detect all functions used). Note that dictionary update takes essentially no time at all, while the `.count()` method occupies the bulk of the time spent executing this function. To reduce this, we essentially have three options: \n",
    "\n",
    "1. We can reduce the time spent executing each `count()` call, by using a faster method. \n",
    "2. We can reduce the number of times `count()` is executed. \n",
    "3. We can completely refactor our code. \n",
    "\n",
    "I don't know of a faster version of `count()`, but it's not hard to dramatically reduce the number of times we execute it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77f5489e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca847a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4 ms ± 66.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9861786d",
   "metadata": {},
   "source": [
    "That's **much** faster! cProfile can tell us why: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4704e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         68 function calls in 0.004 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.004    0.004 <ipython-input-11-85a884abd86e>:1(count_list2)\n",
      "        1    0.000    0.000    0.004    0.004 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.004    0.004 {built-in method builtins.exec}\n",
      "       32    0.003    0.000    0.003    0.000 {method 'count' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "       32    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2811575e",
   "metadata": {},
   "source": [
    "We dramatically reduced the number of times that the `count()` function was called, resulting in a large speed-up. \n",
    "\n",
    "In fact, we can do even better than this by changing our entire strategy. Instead of `count`ing each distinct element, we'll instead simply initialize a count and add to it each time we encounter the appropriate item. This works well because dictionary operations are extremely fast: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a3d3ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7319757d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "821 µs ± 61.1 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c817fbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         3804 function calls in 0.001 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.001    0.001    0.001    0.001 <ipython-input-14-194da5bdcb90>:1(count_list3)\n",
      "        1    0.000    0.000    0.001    0.001 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.001    0.001 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "     3800    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ad4e844",
   "metadata": {},
   "source": [
    "cProfile tells us that we have a large number of calls to `dict.get()`, but access of dictionary elements is exceptionally fast (that's what dictionaries are optimized for), so this doesn't pose a major problem. \n",
    "\n",
    "However, we could do even better still by going back to Question 0: *Should* I write this code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6a6cfe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2318cc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295 µs ± 20.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38e6aa4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         12 function calls in 0.000 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-17-a8d4cf1f8ffb>:3(count_list4)\n",
      "        1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:548(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:617(update)\n",
      "        1    0.000    0.000    0.000    0.000 abc.py:137(__instancecheck__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _collections._count_elements}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8181014",
   "metadata": {},
   "source": [
    "Relative to our initial version of the code, we've achieved a 1000x speedup by relying on built-in functions. Even our relatively efficient hand-written version is roughly 4x slower. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18530af",
   "metadata": {},
   "source": [
    "# Various Tips\n",
    "\n",
    "## Reduce Function Calls\n",
    "\n",
    "The simple act of calling a function in Python can carry some performance overhead. For this reason, reducing the number of times that functions are called can lead to performance improvements, even when there's no otherwise-obvious redundancy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7826f633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "038bdd83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'before gone has one no where go boldly To civilizations new And life new out seek To worlds new strange explore To mission year five Its Enterprise Starship the of voyages the are These frontier final the Space,'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98651c59",
   "metadata": {},
   "source": [
    "This function is logically coded, but it involves many calls to the `__add__` method of strings. Unfortunately, detecting this issue can be difficult for cProfile: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71d03609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.9 µs ± 678 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e40cf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         6 function calls in 0.044 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.036    0.036    0.042    0.042 <ipython-input-20-a9e66526ba01>:1(reverse1)\n",
      "        1    0.002    0.002    0.044    0.044 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.044    0.044 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.006    0.006    0.006    0.006 {method 'split' of 'str' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47696422",
   "metadata": {},
   "source": [
    "The output doesn't make clear that there are any issues involving functions being called multiple times. But if we know to look out for this issue, then we might decide to use other tools, with the benefit of shortening our code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1859214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9235a5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.31 µs ± 55.9 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24832903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         6 function calls in 0.102 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.024    0.024    0.102    0.102 <ipython-input-24-575c4362d720>:1(reverse2)\n",
      "        1    0.000    0.000    0.102    0.102 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.102    0.102 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.074    0.074    0.074    0.074 {method 'join' of 'str' objects}\n",
      "        1    0.003    0.003    0.003    0.003 {method 'split' of 'str' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1351cf4",
   "metadata": {},
   "source": [
    "## Multithreading\n",
    "\n",
    "A popular myth from a few years back asserted that most humans use only 10% of their brain most of the time. This is [not in fact true](https://en.wikipedia.org/wiki/Ten_percent_of_the_brain_myth). What **is** true is that your Python process uses only (about) 10% of the full computational resources of your computer at any given moment. \n",
    "\n",
    "More concretely, most modern personal (Intel-based) computers  possess somewhere between 2 and 6 *cores*, with 4 being perhaps the most common number. Each of these cores usually possesses 2 *threads*. Each thread is a separate process that can be used for executing tasks. When we run Python, we typically do so in a single-threaded environment, which means that our commands are executed by only one of our computer's threads. If your machine has 4 cores, and therefore 8 threads, this corresponds to only 12.5% of your overall CPU resources. \n",
    "\n",
    "*Multithreading* allows us to perform computations using more than one core. For large jobs, this can be beneficial. If your problem admits multithreading, if you use 4 threads, you may be able to finish your computation roughly 4 times as quickly. Nice! \n",
    "\n",
    "### Caution\n",
    "\n",
    "Multithreading sounds exciting, and indeed, it can be a useful thing to do. However, multithreading should usually be your **last** measure for improving performance. Here's why: \n",
    "\n",
    "1. The speedup offered by multithreading is limited by the number of threads available on your computer. In my case, for example, my laptop has 8 threads. This means that the largest possible benefit I could ever obtain from multithreading is an 8x speed up. That's not nothing, but one can often obtain better speedups by revising one's logic and coding constructs, as demonstrated above. \n",
    "2. Multithreading can also place undue burdens on your hardware. There's **a reason** that many processes default to single-threaded runtimes. Your laptop simply isn't built to have all of its computational power engaged all the time. Using many threads for extended periods will likely overheat your system, resulting in thermal throttling. Your CPU will automatically reduce the rate of computation on each thread in order to dissipate heat. Thus, you could actually end up with **slower** code this way. \n",
    "3. There's overhead associated with distributing jobs between threads and syncing them back up. This overhead is manifest both in the time you need to spend writing code in order to manage these processes, and in the actual computation time as well. \n",
    "4. Multithreading really only \"works\" for processes that can be decoupled into independent components or chunks of data. Complex processes in which the current results of computation depend on previous results are often not suitable for multithreading. \n",
    "\n",
    "For these reasons, multithreading should only be considered **after** you're pretty confident that you've exhausted your other means of speeding up your code. \n",
    "\n",
    "### Example\n",
    "\n",
    "Let's finish up with a simple example of multithreading in action. This is a toy example rather than a practical illustration. In a coming Discussion, we will work through some of the important and occasionally subtle associated with successfully deploying multithreading in practice. \n",
    "\n",
    "The simplest way to spawn multiple threads is through the `threading` module. One first defines a function which should be executed on each thread. This function presumably performs some time-intensive computation. One then spawns the desired number of `threading.Thread()` objects with `target` equal to the function which should be executed. Finally, one then `start`s each thread, and calls `join()` to ensure that no code is executed in the main process before each of the spawned threads finishes their work. \n",
    "\n",
    "This example is lightly modified from one presented [here](https://www.geeksforgeeks.org/multithreading-python-set-1/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6185adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import os\n",
    "\n",
    "def task1():\n",
    "    print(\"Task 1 assigned to thread: {}\".format(threading.current_thread().name))\n",
    "    print(\"ID of process running task 1: {}\".format(os.getpid()))\n",
    "    print(\"To boldly go\")\n",
    "    print()\n",
    "    \n",
    "def task2():\n",
    "    print(\"Task 2 assigned to thread: {}\".format(threading.current_thread().name))\n",
    "    print(\"ID of process running task 2: {}\".format(os.getpid()))\n",
    "    print(\"Where no one has gone before\")\n",
    "    print()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e70e1902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID of process running main program: 6724\n",
      "Main thread name: MainThread\n",
      "\n",
      "Task 1 assigned to thread: THREAD 1Task 2 assigned to thread: THREAD 2\n",
      "ID of process running task 2: 6724\n",
      "Where no one has gone before\n",
      "\n",
      "\n",
      "ID of process running task 1: 6724\n",
      "To boldly go\n",
      "\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PIC16B] *",
   "language": "python",
   "name": "conda-env-PIC16B-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
